{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "6478e68d976b40dc9385329c36ef361c",
      "75401b97942b4b10a1b9730737c77098",
      "fec1978e2cd04128bcb08fc257b31f7c",
      "01ef79eff5fd47bb8364533a43194a6c",
      "47958569d18940119389443ad7d31a22",
      "7dbe1bd5fc3f4a20be80b9ca7c5208d1",
      "2239adae3ae1439391dca7ef0e01b116",
      "d02b1747a88d4abca4f4ce5481db3a0e",
      "1ca11b047d5841489753a8e33f64fdb4",
      "1bf178985855448aa72548292c7162eb",
      "62525402ef4e44e981976b0fb12b7e39",
      "c9ef8cbce0154f8699902faa81c56add",
      "de0465edf726444b945e588f621dc7a1",
      "ed75f906383f4d74a5f84d2b9dff19fd",
      "fa69af5fc47d41a99721d4a887ae8715",
      "f432e4c7d10a4795b71dfab5765aacff",
      "f5bdc0de166f4d5d842ce3f062aec750",
      "b726353fc61f46a2a05860b401005715",
      "07ad3d8272f9441faa382e17ce8699b0",
      "5ba8bcfa801d44499a9ee1ff7738d39a",
      "438570d0775a4be9a09a64c793077b29",
      "0194deb02d82476385048445830c4a5f",
      "39e93ba184c4483797ca43a59412c908",
      "224c9ab316dc4de28d5172c6545a69c7",
      "95f025dca1654a3a92ffeff1fb203080",
      "fb7846cb30c641148c308233a05712f2",
      "f2f950d7c5eb46ef9985e691bf47050c",
      "e83045a8292c470aa4f7e08f5bdbf653",
      "f9984826771345438fcbc3779cd15cef",
      "b5b08fd8c4934c35bd63f8e8c415fc60",
      "fe48360c1b62430eb8430eb02f12bec6",
      "5f9e23a3111847938d77790e63835e4d",
      "758aa6a5860c4255a5036bf7daea59eb",
      "9304eb6c66d54f0bbbf2f3e3ed31b849",
      "687abf10ee124992bbbc5011a10b3bd1",
      "bb7b29491396460a8593db21e0ef2d11",
      "945e18c33de648ab965f844da8d8ba2d",
      "9a87f13d893143afb2f7f8318ecfd9d2",
      "11225498e71a4eddb115fea2bfc4c358",
      "9b8491d4bc934e638450210631466f33",
      "86ef55655d10450291f2dca5db5b86b4",
      "ea8c6ca623b54ffd85c7601d742e683d",
      "42239ae6e87a4ac7bb671ca7747a815a",
      "4ce048714e24495e8bd00187b1aaa06f",
      "76d4f9d109264443b64adfed614ab8d1",
      "42bb6508488f4a90918997bf33de625f",
      "a696b34c3ce34d78a0f57aed88708792",
      "324f5a1c93ad45fdb78c6e65680002eb",
      "705b51a71de54f1ba9552e03d6937348",
      "3e3109e063184b0b83deec342af22f18",
      "cbe55898d843457db9ebc36d71b99357",
      "c4dfb08c9bce4d9b9c7737fe11d2cebc",
      "e3694451e3d5449b8eb6a1bc4bd34b21",
      "e4b71b4dfc744f2ea7238d775d5077ca",
      "7732a236736246f997abd2a8c173d6f8",
      "d0cc8f266389473fbef422537fc778b7",
      "b879cef5352e4be0b02105aed64301cd",
      "3fdd251dd36f4257938752fb25600a61",
      "e56433cc11214dc8945cbcde150f64f8",
      "3111c75f50ce441388183edcab96aba6",
      "70f54d2945164ea4b07bcc2308a7f39b",
      "9a8cc32e754a4db8978f35da287249cc",
      "c9ad7e6633004f2dab40c8939cbb3209",
      "eb09f9b0291d4fe69f65ffe74eb1053e",
      "3cc14ee02b494f31a402981fc503128b",
      "553b118c8ae04594bd3e632de70798db",
      "f924e757512647e1a820be273370e6e5",
      "5a3f591e68544bb9a73f2524cb3bedaa",
      "207475b76b604a41b2e570fb3bdf404f",
      "3c2bc9e42d5846259ea9d4c76201266a",
      "a4327805408e47098eca4d80ee148fa1",
      "2145070d6ac04d8c855afde295e9c6be",
      "aa3590c5f5834b9c84fa038a95a6866a",
      "d8f9d75c28d24bc7be0ae9fb0a698e07",
      "9b990541d942402ca6a1605ed362179a",
      "5ad18d734da64a238b41817beabacf1c",
      "8228a143a034413aac00385e726b4dff",
      "2384d3f437ed4f6cb694a2d0f80e8e25",
      "f9e82afada9b4b94b5229accce292bb9",
      "ece709062e40413c83428fabfc09d213",
      "036297987acd44c9ac215e2868e8ed7a",
      "3e7d8b14ac8144c3a7a524167de90cce",
      "be16f7eefe38489688bedb79ee3da918",
      "56b5b04cf63d43f8bb70d4c367a01395",
      "04be18e077e84247b6bb3297323072a6",
      "80d6633f6e844020a523b4a3485e17ab",
      "afa38fcff79f4c6788f2b104d41a13c5",
      "20aa3bd0564f44d9b8816e99586864ac",
      "6593c8962c6340cd92454bb55757ea56",
      "fa692de5d2854bfd89d7c63231e27fe4",
      "94858c2ef5da4cd3aebd3c4ce59e0d0f",
      "6c9bbff4f0564ff7a92e5657686ca742",
      "ce110b6466bb407ba68db73481ddca70",
      "2cc4ddd6a3b2406e9d9c5754c131f914",
      "f5460b80a5e144e4992f27e73af8c328",
      "1bd46f3eeb8b4b9da4157485f1e91560",
      "50d5a882d84e4f2db74502b1bdca45cf",
      "792ff7af9d2d4019a7b636ccbf1d960f",
      "80fcd1bba1574286bb07187914e82057",
      "b79b280d2a324b9a9d2f2cfe884076ef",
      "66cad8a3e87b42ca8ff4b143d8488396",
      "88cee14461714a7caffb35dba023d29f",
      "574a8b85dd8e4c628981d0e601341d0a",
      "f7a7721f38a6486ab48fa876db675bff",
      "58bbc56a2b7b4552a96843ccdc35f936",
      "aa43122ee30b4a66a6806c2378c9c7c4",
      "88797527dc4a4f5c892d690989d68609",
      "1095634d374d4fb182c43281b5fafcb9",
      "20e015631465422f9310eda1ac23d18f",
      "5e20303b060740cba7124fb2c02df687"
     ]
    },
    "executionInfo": {
     "elapsed": 51400,
     "status": "ok",
     "timestamp": 1760894980311,
     "user": {
      "displayName": "Yokeshwaran Goppinat",
      "userId": "14819290310669589320"
     },
     "user_tz": -330
    },
    "id": "vd3rief_H8LF",
    "outputId": "1cc01f7a-1d09-4f20-b51f-634b38819987"
   },
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Result Summary w/ Relative Drops (Teacher vs LoRA adapters)\n",
    "# Paste & run as one cell in Colab\n",
    "# ============================\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "!pip install -q transformers datasets evaluate accelerate peft openpyxl\n",
    "\n",
    "import os, json, math, pprint\n",
    "import numpy as np, pandas as pd, torch\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n",
    "from peft import PeftModel\n",
    "import evaluate\n",
    "\n",
    "# ---------- USER SETTINGS (edit if needed) ----------\n",
    "DRIVE_BASE = \"/content/drive/MyDrive/Colab Notebooks/HindiCodeMix\"\n",
    "DRIVE_BASE_LoRA = \"/content/drive/MyDrive/Colab Notebooks/LoRA/HindiCodeMix\"\n",
    "SPLIT_BASE = \"/content/drive/MyDrive/Colab Notebooks/HindiCodeMix/data_processed\"\n",
    "TEACHER_DIR = os.path.join(DRIVE_BASE, \"results_teacher_4epoch\", \"model\")\n",
    "TOKENIZER_DIR = os.path.join(os.path.dirname(TEACHER_DIR), \"tokenizer\")\n",
    "TEST_CSV = os.path.join(SPLIT_BASE, \"test.csv\")\n",
    "ADAPTERS_ROOT = \"/content/drive/MyDrive/Colab Notebooks/LoRA/HindiCodeMix/DropOut_0.05\"  # folder containing adapter subfolders\n",
    "\n",
    "OUT_CSV = os.path.join(DRIVE_BASE_LoRA, \"lora_result_summary_with_drops_out0.05.csv\")\n",
    "OUT_XLSX = os.path.join(DRIVE_BASE_LoRA, \"lora_result_summary_with_drops_out0.05.xlsx\")\n",
    "OUT_PLOT = os.path.join(DRIVE_BASE_LoRA, \"lora_results_plots_with_drops_out0.05.png\")\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_EVAL = 32\n",
    "MAX_LEN = 64\n",
    "\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "\n",
    "# ---------- Sanity checks ----------\n",
    "if not os.path.exists(TEST_CSV):\n",
    "    raise FileNotFoundError(f\"Test CSV not found at {TEST_CSV}\")\n",
    "\n",
    "test_df = pd.read_csv(TEST_CSV)\n",
    "if \"review\" not in test_df.columns or \"label\" not in test_df.columns:\n",
    "    raise RuntimeError(\"test.csv must contain columns 'review' and 'label'.\")\n",
    "\n",
    "texts = test_df[\"review\"].astype(str).tolist()\n",
    "labels = test_df[\"label\"].astype(int).tolist()\n",
    "\n",
    "# ---------- Load tokenizer ----------\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_DIR, use_fast=True, local_files_only=True)\n",
    "    print(\"Loaded tokenizer from:\", TOKENIZER_DIR)\n",
    "except Exception as e:\n",
    "    print(\"Local tokenizer load failed:\", e, \"\\nFalling back to distilbert-base-multilingual-cased\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-multilingual-cased\", use_fast=True)\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    if tokenizer.eos_token is not None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    else:\n",
    "        tokenizer.add_special_tokens({\"pad_token\": \"[PAD]\"})\n",
    "\n",
    "enc = tokenizer(texts, truncation=True, padding=\"max_length\", max_length=MAX_LEN, return_tensors=\"pt\")\n",
    "indices = list(range(len(texts)))\n",
    "batches = [indices[i:i+BATCH_EVAL] for i in range(0, len(indices), BATCH_EVAL)]\n",
    "\n",
    "# ---------- Metrics helpers ----------\n",
    "acc_metric = evaluate.load(\"accuracy\")\n",
    "f1_metric  = evaluate.load(\"f1\")\n",
    "\n",
    "def eval_model_logits(model, device):\n",
    "    model.to(device).eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx in tqdm(batches, desc=\"Eval batches\"):\n",
    "            inp = { \"input_ids\": enc[\"input_ids\"][batch_idx].to(device),\n",
    "                    \"attention_mask\": enc[\"attention_mask\"][batch_idx].to(device) }\n",
    "            if \"token_type_ids\" in enc:\n",
    "                inp[\"token_type_ids\"] = enc[\"token_type_ids\"][batch_idx].to(device)\n",
    "            out = model(**inp)\n",
    "            logits = getattr(out, \"logits\", out[0] if isinstance(out, (list,tuple)) else out)\n",
    "            if hasattr(logits, \"detach\"):\n",
    "                preds = torch.argmax(logits, dim=-1).cpu().numpy().tolist()\n",
    "            else:\n",
    "                preds = np.argmax(np.asarray(logits), axis=-1).tolist()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend([labels[i] for i in batch_idx])\n",
    "    acc = float(acc_metric.compute(predictions=all_preds, references=all_labels)[\"accuracy\"])\n",
    "    f1  = float(f1_metric.compute(predictions=all_preds, references=all_labels, average=\"macro\")[\"f1\"])\n",
    "    return acc, f1\n",
    "\n",
    "def count_total_params(model):\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "def count_trainable_params(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def folder_on_disk_size_bytes(path):\n",
    "    total = 0\n",
    "    for root, _, files in os.walk(path):\n",
    "        for f in files:\n",
    "            try:\n",
    "                total += os.path.getsize(os.path.join(root, f))\n",
    "            except Exception:\n",
    "                pass\n",
    "    return total\n",
    "\n",
    "# ---------- Load teacher ----------\n",
    "if not os.path.isdir(TEACHER_DIR):\n",
    "    raise RuntimeError(f\"Teacher model not found at {TEACHER_DIR}\")\n",
    "print(\"Loading teacher from\", TEACHER_DIR)\n",
    "teacher = AutoModelForSequenceClassification.from_pretrained(TEACHER_DIR, local_files_only=True, output_attentions=True, output_hidden_states=True)\n",
    "teacher_acc, teacher_f1 = eval_model_logits(teacher, DEVICE)\n",
    "teacher_total_params = count_total_params(teacher)\n",
    "teacher_disk_bytes = folder_on_disk_size_bytes(TEACHER_DIR)\n",
    "print(f\"Teacher -> Acc: {teacher_acc:.4f}, Macro-F1: {teacher_f1:.4f}, Params: {teacher_total_params:,}\")\n",
    "\n",
    "records = []\n",
    "records.append({\n",
    "    \"Label\": \"Teacher\",\n",
    "    \"Accuracy\": teacher_acc,\n",
    "    \"Macro-F1\": teacher_f1,\n",
    "    \"TotalParams\": teacher_total_params,\n",
    "    \"TrainableParams\": teacher_total_params,\n",
    "    \"DiskBytes\": teacher_disk_bytes,\n",
    "    \"ParamReduction%\": None,\n",
    "    \"RelAccDrop%\": None,\n",
    "    \"RelF1Drop%\": None,\n",
    "    \"Path\": TEACHER_DIR,\n",
    "    \"Notes\": \"teacher\"\n",
    "})\n",
    "\n",
    "teacher.to(\"cpu\"); del teacher; torch.cuda.empty_cache()\n",
    "\n",
    "# ---------- Discover adapters ----------\n",
    "adapter_dirs = []\n",
    "if os.path.isdir(ADAPTERS_ROOT):\n",
    "    for name in sorted(os.listdir(ADAPTERS_ROOT)):\n",
    "        full = os.path.join(ADAPTERS_ROOT, name)\n",
    "        if os.path.isdir(full):\n",
    "            # heuristic: directory with adapter artifacts or metadata\n",
    "            files = os.listdir(full)\n",
    "            markers = {\"adapter_config.json\",\"pytorch_model.bin\",\"adapter_results.json\",\"pytorch_model.bin.index.json\"}\n",
    "            if markers.intersection(files) or any(f.startswith(\"pytorch_model\") for f in files):\n",
    "                adapter_dirs.append(full)\n",
    "            else:\n",
    "                # search nested\n",
    "                for root, _, fns in os.walk(full):\n",
    "                    if markers.intersection(fns):\n",
    "                        adapter_dirs.append(full); break\n",
    "else:\n",
    "    print(\"ADAPTERS_ROOT not found:\", ADAPTERS_ROOT)\n",
    "\n",
    "print(\"Detected adapters:\", adapter_dirs)\n",
    "\n",
    "# ---------- Evaluate adapters ----------\n",
    "for adp in adapter_dirs:\n",
    "    print(\"\\nProcessing adapter:\", adp)\n",
    "    meta = {}\n",
    "    meta_path = os.path.join(adp, \"adapter_results.json\")\n",
    "    if os.path.exists(meta_path):\n",
    "        try:\n",
    "            meta = json.load(open(meta_path, \"r\"))\n",
    "        except Exception:\n",
    "            meta = {}\n",
    "\n",
    "    # try to load as PEFT adapter (preferred)\n",
    "    try:\n",
    "        base_for_eval = AutoModelForSequenceClassification.from_pretrained(TEACHER_DIR, local_files_only=True, config=AutoConfig.from_pretrained(TEACHER_DIR))\n",
    "    except Exception:\n",
    "        base_for_eval = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-multilingual-cased\", num_labels=2)\n",
    "\n",
    "    try:\n",
    "        peft_loaded = PeftModel.from_pretrained(base_for_eval, adp, is_trainable=False)\n",
    "        peft_loaded.to(DEVICE)\n",
    "        acc, f1 = eval_model_logits(peft_loaded, DEVICE)\n",
    "        total_p = count_total_params(peft_loaded)\n",
    "        train_p = count_trainable_params(peft_loaded)\n",
    "        disk_b = folder_on_disk_size_bytes(adp)\n",
    "\n",
    "        rel_acc = round(100.0 * (teacher_acc - acc) / teacher_acc, 4) if teacher_acc else None\n",
    "        rel_f1  = round(100.0 * (teacher_f1 - f1) / teacher_f1, 4) if teacher_f1 else None\n",
    "        param_red = round(100.0 * (1.0 - (train_p / teacher_total_params)), 4)\n",
    "\n",
    "        records.append({\n",
    "            \"Label\": os.path.basename(adp),\n",
    "            \"Accuracy\": round(acc, 6),\n",
    "            \"Macro-F1\": round(f1, 6),\n",
    "            \"TotalParams\": total_p,\n",
    "            \"TrainableParams\": train_p,\n",
    "            \"DiskBytes\": disk_b,\n",
    "            \"ParamReduction%\": param_red,\n",
    "            \"RelAccDrop%\": rel_acc,\n",
    "            \"RelF1Drop%\": rel_f1,\n",
    "            \"Path\": adp,\n",
    "            \"Notes\": meta.get(\"notes\", \"peft_adapter\")\n",
    "        })\n",
    "\n",
    "        peft_loaded.to(\"cpu\"); del peft_loaded; del base_for_eval; torch.cuda.empty_cache()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"PEFT load failed for\", adp, \"â€” trying to load as full model:\", e)\n",
    "        try:\n",
    "            model_full = AutoModelForSequenceClassification.from_pretrained(adp, local_files_only=True, output_attentions=True, output_hidden_states=True)\n",
    "            acc, f1 = eval_model_logits(model_full, DEVICE)\n",
    "            total_p = count_total_params(model_full)\n",
    "            train_p = count_trainable_params(model_full)\n",
    "            disk_b = folder_on_disk_size_bytes(adp)\n",
    "\n",
    "            rel_acc = round(100.0 * (teacher_acc - acc) / teacher_acc, 4) if teacher_acc else None\n",
    "            rel_f1  = round(100.0 * (teacher_f1 - f1) / teacher_f1, 4) if teacher_f1 else None\n",
    "            param_red = round(100.0 * (1.0 - (train_p / teacher_total_params)), 4)\n",
    "\n",
    "            records.append({\n",
    "                \"Label\": os.path.basename(adp),\n",
    "                \"Accuracy\": round(acc,6),\n",
    "                \"Macro-F1\": round(f1,6),\n",
    "                \"TotalParams\": total_p,\n",
    "                \"TrainableParams\": train_p,\n",
    "                \"DiskBytes\": disk_b,\n",
    "                \"ParamReduction%\": param_red,\n",
    "                \"RelAccDrop%\": rel_acc,\n",
    "                \"RelF1Drop%\": rel_f1,\n",
    "                \"Path\": adp,\n",
    "                \"Notes\": \"full-model\"\n",
    "            })\n",
    "\n",
    "            model_full.to(\"cpu\"); del model_full; torch.cuda.empty_cache()\n",
    "        except Exception as e2:\n",
    "            print(\"Failed to load adapter or full model for\", adp, \"=>\", e2)\n",
    "            continue\n",
    "\n",
    "# ---------- Build dataframe & format ----------\n",
    "df = pd.DataFrame(records)\n",
    "if df.empty:\n",
    "    print(\"No records found.\")\n",
    "else:\n",
    "    # numeric formatting\n",
    "    df[\"Accuracy\"] = df[\"Accuracy\"].astype(float).round(6)\n",
    "    df[\"Macro-F1\"] = df[\"Macro-F1\"].astype(float).round(6)\n",
    "    df[\"Params(M)\"] = (df[\"TotalParams\"].astype(float) / 1e6).round(4)\n",
    "    df[\"AdapterParams(K)\"] = (df[\"TrainableParams\"].astype(float) / 1e3).round(3)\n",
    "    df[\"Disk(MB)\"] = (df[\"DiskBytes\"].astype(float) / (1024*1024)).round(4)\n",
    "    df[\"ParamReduction%\"] = df[\"ParamReduction%\"].astype(float).round(4)\n",
    "    # ensure rel drop cols exist\n",
    "    if \"RelAccDrop%\" not in df.columns: df[\"RelAccDrop%\"] = None\n",
    "    if \"RelF1Drop%\" not in df.columns: df[\"RelF1Drop%\"] = None\n",
    "    df[\"RelAccDrop%\"] = df[\"RelAccDrop%\"].astype(float).round(4)\n",
    "    df[\"RelF1Drop%\"] = df[\"RelF1Drop%\"].astype(float).round(4)\n",
    "\n",
    "    # order: teacher first, then adapters sorted by Macro-F1 desc\n",
    "    teacher_row = df[df[\"Label\"]==\"Teacher\"]\n",
    "    others = df[df[\"Label\"]!=\"Teacher\"].sort_values(by=\"Macro-F1\", ascending=False)\n",
    "    df_out = pd.concat([teacher_row, others], ignore_index=True)\n",
    "\n",
    "    cols_present = [\"Label\",\"Accuracy\",\"Macro-F1\",\"Params(M)\",\"AdapterParams(K)\",\"ParamReduction%\",\"RelAccDrop%\",\"RelF1Drop%\",\"Disk(MB)\",\"Path\",\"Notes\"]\n",
    "    cols_present = [c for c in cols_present if c in df_out.columns]\n",
    "    df_final = df_out[cols_present].reset_index(drop=True)\n",
    "\n",
    "    df_final.to_csv(OUT_CSV, index=False)\n",
    "    try:\n",
    "        df_final.to_excel(OUT_XLSX, index=False)\n",
    "    except Exception as e:\n",
    "        print(\"Excel save failed:\", e)\n",
    "\n",
    "    print(\"\\nSaved summary to:\", OUT_CSV, OUT_XLSX)\n",
    "    display(df_final)\n",
    "\n",
    "    # ---------- Plots ----------\n",
    "    if not df_final.empty:\n",
    "        plt.figure(figsize=(12,5))\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.scatter(df_final[\"Params(M)\"], df_final[\"Accuracy\"])\n",
    "        for i,row in df_final.iterrows():\n",
    "            plt.annotate(row[\"Label\"], (row[\"Params(M)\"], row[\"Accuracy\"]))\n",
    "        plt.xlabel(\"Params (M)\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.title(\"Accuracy vs Model Size\")\n",
    "\n",
    "        plt.subplot(1,2,2)\n",
    "        x = df_final[\"ParamReduction%\"].fillna(0)\n",
    "        y = df_final[\"Macro-F1\"]\n",
    "        plt.scatter(x, y)\n",
    "        for i,row in df_final.iterrows():\n",
    "            plt.annotate(row[\"Label\"], (row[\"ParamReduction%\"], row[\"Macro-F1\"]))\n",
    "        plt.xlabel(\"ParamReduction%\")\n",
    "        plt.ylabel(\"Macro-F1\")\n",
    "        plt.title(\"ParamReduction% vs Macro-F1\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(OUT_PLOT, dpi=200)\n",
    "        print(\"Saved plots to:\", OUT_PLOT)\n",
    "        display(plt.show())\n",
    "\n",
    "print(\"Done.\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM/1jDwl+Q45khEpSpPrep2",
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
