{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 853,
     "referenced_widgets": [
      "6ac8fcc6bd444d4196323006401648bf",
      "8c04d532a5614a23ac4518b3fba06391",
      "76e96e5df1b64523a270bf30e29d14d1",
      "4399f84a5c2e4bdea4645b121579b1b0",
      "bee0462cf76743f7bc1fbc967da69c50",
      "1587f8a31a83443694c18f7a917c1ec2",
      "6748c50452c4420c8947c6ba83c757a1",
      "3164482252cf4fab8cfca0386110ee9a",
      "1db11aa68bc641af894963b42ee41d3b",
      "7864592d50cc4e8eb86de396b4f985ba",
      "01df40ae8f8a4e35988837a4566c7293",
      "d891a3c3c9ef4143973e882be4076652",
      "7d8af638f747437d910cb45dd5419972",
      "db227a7c372041efb54a04b72f6ef358",
      "d8ba1418f75f4a319274099aa8d2b3b8",
      "01fd86bb34244dae8cfd5b3614b11618",
      "a72d13a6bd0e4635bc13de38937dd555",
      "8950a76cf6be486ab05182e22f9e4e4d",
      "43b1abfbf8ed47e09b1f824611d921d6",
      "8ef00aaa1fe645e4ad8f11ebaed7cfa6",
      "aae73b1cd61448efb77e97aca2fe2778",
      "a50d944864214a7f9be9bbc1c07925b2",
      "b9204b591c71456085548735be3dfd56",
      "6b749537c27844dabd7ad5b526c429a7",
      "172ae633e7fe4cdc92207417e5431231",
      "3e2d324877b84437b7d06ddaa7770d11",
      "5f252e6d64954b9098a2127548270aba",
      "a645d2fd565d4fdcbbdc74e5ad655d23",
      "b86623c05f1547449bf133530a4e21f2",
      "03a86a4efb9444758410fb9e624beb5f",
      "1a98b14828fd4c1b90e9fb2d600b0eea",
      "fb13d0524e6f44efaa62ac366970662f",
      "3d586f95565b49bc98a923456527e4af",
      "810873c0d1644432b92a075087e76b61",
      "be5941f6b663430ab759f54a673ca480",
      "04d7e917dcf9457e8296a414d7c3d76f",
      "9fd6c53d1fcd4a2c9e737cfd35b47d29",
      "f68b3861b977452d83c1dcec03f7fd1e",
      "1fa3217a43564dd0a2efb5623dba79fc",
      "8d83e3274256492d954be198afc81f13",
      "0c5bef21dbf1451bbe64a70697f14d63",
      "97042272d2214588b4bedad9a6943ee7",
      "e269bee7fef54c85a4a8a1c4b0bc72c8",
      "89c2959fdbe84b68883b32d3f467b575",
      "aca25464c21042b9bdc15a985d8978e1",
      "536d1e2a901b4a39bfa20f288695be4a",
      "a09b7065230a4564adc38e030546b2a8",
      "deea74388f30441ca8ed3f078540285f",
      "59b2e5daf31646d1a189f5612e169514",
      "4a6c76f2c7b54ad4be9528be85fb2f4a",
      "72766deeaccc41fc80f63fd2a941c0b3",
      "a66ed5842b354b68aa1c205022067f50",
      "d731545a3bac45aabb3de0ba5c652a06",
      "7a16bae72fbc46d6b0b8a9fe1cf46f97",
      "ede343ad1c3b482fa51b528b95a18739",
      "0b565dd477f44186b0d4be4af89d9a0b",
      "642cf468ff244f64891ee8f77321ae2f",
      "0a83390ce3304959955186be9ce9d0e4",
      "fbaba192c7b140b6ac062544af8d88f7",
      "829a36f7d2b144be87fec2259fe6148e",
      "6109017aa1cf4cbbbace5319c9e8cd29",
      "cf25dbfa026d449c8986a67471bd5a7f",
      "135b4da98b8f400dabf4fc797b0104b2",
      "408f109fac094ec682537b9c63d60074",
      "fc00565e847349a891beb948a579ba99",
      "6583635ff1cf4470831301b877ca570e",
      "eaf8c16f48354ba78d09ae8a96d42583",
      "01b161c92a6a4b638a7455cdebbce1bb",
      "e97f9d2ea7cc4f8f9f7ca8f10fc67b34",
      "dba3ad15f41c464b941b5304c2404f7e",
      "df39cf5e1ce64d438703222f8868b59a",
      "b46c4f35b9a3444d8953c78c464d0dcf",
      "0741d8fd4a8b4d3e9052ac3581cec82a",
      "2382db749f604789a0472c4c84aaee9c",
      "9180447fea654c98aec819be7557453b",
      "e14c8ea25f764fa59405e4212cb3aba7",
      "2bbd3085846140128d6f37fc05951548",
      "42ea4c0ced884bd48d167598fd7a1d5e",
      "d6f410134ce24b75b6f97d0cf7bf2b22",
      "a45e37c232e5426c830c0bee196001fa",
      "e27ce336242f4a4c8f045a2042bfc0cc",
      "8f60db049fb642bc8ec824d3d381430e",
      "b629cc37ccba45bd9ac91d1a957809ae",
      "43072361f98244c8b53e746ecec5adc5",
      "8747a2b1b86647e4a11e898e690e0974",
      "856b878f188949069bf944b7264c7e31",
      "ec28c453aef54465b68da2b9bda62eaf",
      "54c746f8fa8649b6b899a0f5712541fe",
      "e179e51152a74dce904d4278ec1a2380",
      "0ce65678fcf7473fa953bc7eb91134e5",
      "b689bc72665546fba77c367fadd8d980",
      "c081b72466654fe582c27c79a864dc56",
      "33541a5ab9964887abcb983a0e89bf18",
      "57689393227e4631837c2ff09f83e9ee",
      "e793847c0626486998ed7ad0ec05f4ce",
      "9ce8532f87284e3a951e7d64e1c2be7b",
      "eb2433b0a74044eca95f8e6a5f1cdcfb",
      "3d735bba9f4f4ab98d25ba82d5cf825e",
      "972bd9712f024373951ba19015475f3a",
      "3981cdfb192b4ad79bafa23ae56188fa",
      "27c8ec3788be4854b9e57911bc0f953f",
      "dde599a38f2a4bf08fcfc49858102cce",
      "1479bac60a2042b5aa0ae14b33d9bbd7",
      "d3e59201114d41dc944ec9aab9a0adff",
      "c36845dbaa044339863a4e2f4101d687",
      "6a0e98467a874e3d914c0fabeb383538",
      "e7ad04d19de44a698a0098ba9b047ceb",
      "b4b272e6092f426bb38afcce9ec6e3ea",
      "b9612aa5491c4833a239a882d68f7644",
      "8b2cf06b5f7f478ca7301552d5a5cadd",
      "5cd872189d7a4f249dd2a31aa9f1f73d",
      "84d67b1dd1be483a8a0dcee84c7e21b1",
      "f8b2165971b640a78c3bcfaf884b06e1",
      "fac7b0325cce4cb097ff74d6fce41561",
      "4d8a982bcbed4e6b9f730c5fca57ccb9",
      "73e1d3525be44861b2e6d4326ab4c43a",
      "41d98307537d4dc7a948535a45cba316",
      "90e00f5662694945bb64fcb10c45bba6",
      "7991721774634319a6efb86f74963bae",
      "5890c68abdf24da89e38d85bf450e199",
      "ccb12e1c101546aabece82fc84900f99",
      "c1c2e0f0b0e64313a56aacca22c1f7dc",
      "a350a0e4292b4a269e5958c0e79fb7bf",
      "6781c43656fd4773886eab6f47606f79",
      "f28a942ce6f74bee99bf25738d04a7ae",
      "af079862011b4fccbd5f92ec78b2ef07",
      "d630fad978744939b7c9016e967a0adc",
      "f73845910ff74e3fa006a99fc5f3e974",
      "3cc045ffde7443af93ce3ae926d0042a",
      "3b0043d6f06a4601b8fe252a6e0cd5e0",
      "a11e2d1fcd1048029d4064c48ac0fd9e",
      "f0ad7f0538304e93abe1d2da1a81b85c",
      "2fab2852745e4521ba0d29e49f4af5ca",
      "634e1ab61d9d44a28dbb720410143617",
      "30ad60a5cd3e4644ba739ecbdb47c284",
      "6c18906afbbc4e99b7397fa7b9f37d17",
      "4043bb7ea2c047fe9d7b5c3422088f63",
      "44f582d984f24fdb91190950e617ff17",
      "22316c4bbbcd452e86ddfdc5d409cfdb",
      "e1ad8c3eba53497c951851f6e2f67e1e",
      "21597c105f394011b9e83f6f6f332be7",
      "056fd4df485f4710a2454f5af042da36",
      "c1dfd8a209e04eb6b7fccce060cf5746"
     ]
    },
    "executionInfo": {
     "elapsed": 270459,
     "status": "ok",
     "timestamp": 1759212349358,
     "user": {
      "displayName": "Yokeshwaran Goppinat",
      "userId": "14819290310669589320"
     },
     "user_tz": -330
    },
    "id": "L9g93ubGHJiK",
    "outputId": "7e776911-cd15-4ecd-98ea-bfd95329e5ef"
   },
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Teacher Training (4 epochs, save to results_teacher_4epoch)\n",
    "# Paste & run as a single cell in Colab\n",
    "# -------------------------\n",
    "\n",
    "# 0) Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "# 1) Install dependencies\n",
    "!pip install -q transformers datasets evaluate accelerate\n",
    "\n",
    "# 2) Imports\n",
    "import os, gc, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import evaluate\n",
    "from datasets import Dataset, DatasetDict, Value\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoConfig, AutoModelForSequenceClassification,\n",
    "    Trainer, TrainingArguments, DataCollatorWithPadding, set_seed\n",
    ")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 3) Paths & settings\n",
    "DRIVE_BASE = \"/content/drive/MyDrive/Colab Notebooks/CodeMix\"\n",
    "train_path = os.path.join(DRIVE_BASE, \"train.csv\")\n",
    "val_path   = os.path.join(DRIVE_BASE, \"val.csv\")\n",
    "test_path  = os.path.join(DRIVE_BASE, \"test.csv\")\n",
    "\n",
    "# NEW: save to a separate folder so we don't overwrite previous teacher results\n",
    "RESULTS_DIR = os.path.join(DRIVE_BASE, \"results_teacher_4epoch\")\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "SEED = 42\n",
    "set_seed(SEED)\n",
    "\n",
    "CHECKPOINT = \"distilbert-base-multilingual-cased\"\n",
    "MAX_LEN = 64\n",
    "\n",
    "# OOM-safe defaults (you can tune later)\n",
    "PER_DEVICE_BATCH = 4\n",
    "GRAD_ACCUM = 2\n",
    "EPOCHS = 4          # <-- changed to 4 epochs\n",
    "LR = 2e-5\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# 4) Load CSVs (from data_prep notebook)\n",
    "if not os.path.exists(train_path) or not os.path.exists(val_path) or not os.path.exists(test_path):\n",
    "    raise FileNotFoundError(\"Expected train/val/test CSVs under DRIVE_BASE. Run data_prep notebook first.\")\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "val_df   = pd.read_csv(val_path)\n",
    "test_df  = pd.read_csv(test_path)\n",
    "print(\"Train/Val/Test sizes:\", len(train_df), len(val_df), len(test_df))\n",
    "\n",
    "# 5) Hugging Face DatasetDict\n",
    "dataset = DatasetDict({\n",
    "    \"train\": Dataset.from_pandas(train_df.reset_index(drop=True)),\n",
    "    \"validation\": Dataset.from_pandas(val_df.reset_index(drop=True)),\n",
    "    \"test\": Dataset.from_pandas(test_df.reset_index(drop=True)),\n",
    "})\n",
    "\n",
    "# 6) Tokenizer + tokenization\n",
    "tokenizer = AutoTokenizer.from_pretrained(CHECKPOINT)\n",
    "\n",
    "def tokenize_fn(batch):\n",
    "    # pad all sequences to the same MAX_LEN for safety\n",
    "    return tokenizer(batch[\"review\"], truncation=True, padding=\"max_length\", max_length=MAX_LEN)\n",
    "\n",
    "# Tokenize (drop original columns to avoid duplicates)\n",
    "dataset = dataset.map(tokenize_fn, batched=True, remove_columns=dataset[\"train\"].column_names)\n",
    "\n",
    "# Re-add labels (ensure int)\n",
    "dataset[\"train\"] = dataset[\"train\"].add_column(\"label\", train_df[\"label\"].astype(int).tolist())\n",
    "dataset[\"validation\"] = dataset[\"validation\"].add_column(\"label\", val_df[\"label\"].astype(int).tolist())\n",
    "dataset[\"test\"] = dataset[\"test\"].add_column(\"label\", test_df[\"label\"].astype(int).tolist())\n",
    "\n",
    "# 7) Force label to int64\n",
    "for split in [\"train\", \"validation\", \"test\"]:\n",
    "    dataset[split] = dataset[split].cast_column(\"label\", Value(\"int64\"))\n",
    "\n",
    "# 8) Torch format\n",
    "cols = [\"input_ids\", \"attention_mask\", \"label\"]\n",
    "if \"token_type_ids\" in dataset[\"train\"].column_names:\n",
    "    cols.insert(1, \"token_type_ids\")\n",
    "dataset.set_format(type=\"torch\", columns=cols)\n",
    "\n",
    "# Data collator\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Check one sample\n",
    "sample = dataset[\"train\"][0]\n",
    "print(\"Sample keys:\", list(sample.keys()), \"len(input_ids):\", len(sample[\"input_ids\"]), \"label:\", sample[\"label\"])\n",
    "\n",
    "# 9) Teacher model\n",
    "num_labels = 2\n",
    "teacher_config = AutoConfig.from_pretrained(\n",
    "    CHECKPOINT,\n",
    "    num_labels=num_labels,\n",
    "    output_hidden_states=True,\n",
    "    output_attentions=True\n",
    ")\n",
    "teacher = AutoModelForSequenceClassification.from_pretrained(CHECKPOINT, config=teacher_config).to(device)\n",
    "\n",
    "# optionally enable gradient checkpointing if supported (saves memory)\n",
    "try:\n",
    "    teacher.gradient_checkpointing_enable()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# 10) Metrics\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    if isinstance(logits, tuple):\n",
    "        logits = logits[0]\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_metric.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
    "        \"macro_f1\": f1_metric.compute(predictions=preds, references=labels, average=\"macro\")[\"f1\"]\n",
    "    }\n",
    "\n",
    "# 11) TrainingArguments helper (compatibility)\n",
    "def make_train_args(output_dir, **kwargs):\n",
    "    ta_kwargs = dict(kwargs)\n",
    "    # support different HF versions which may have different arg names\n",
    "    if \"evaluation_strategy\" in TrainingArguments.__init__.__code__.co_varnames:\n",
    "        if \"eval_strategy\" in ta_kwargs:\n",
    "            ta_kwargs[\"evaluation_strategy\"] = ta_kwargs.pop(\"eval_strategy\")\n",
    "    else:\n",
    "        if \"evaluation_strategy\" in ta_kwargs:\n",
    "            ta_kwargs[\"eval_strategy\"] = ta_kwargs.pop(\"evaluation_strategy\")\n",
    "    return TrainingArguments(output_dir=output_dir, **ta_kwargs)\n",
    "\n",
    "train_args = make_train_args(\n",
    "    output_dir=RESULTS_DIR,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=PER_DEVICE_BATCH,\n",
    "    per_device_eval_batch_size=PER_DEVICE_BATCH,\n",
    "    gradient_accumulation_steps=GRAD_ACCUM,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    learning_rate=LR,\n",
    "    logging_steps=50,\n",
    "    report_to=\"none\",\n",
    "    fp16=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "# 12) Trainer\n",
    "trainer_teacher = Trainer(\n",
    "    model=teacher,\n",
    "    args=train_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# 13) Train\n",
    "print(\"Starting teacher training (4 epochs)...\")\n",
    "trainer_teacher.train()\n",
    "\n",
    "# 14) Evaluate\n",
    "teacher_eval = trainer_teacher.evaluate(dataset[\"test\"])\n",
    "print(\"Teacher test results:\", teacher_eval)\n",
    "\n",
    "# 15) Save model + tokenizer into the results_teacher_4epoch folder\n",
    "teacher_save_dir = os.path.join(RESULTS_DIR, \"model\")\n",
    "tokenizer_save_dir = os.path.join(RESULTS_DIR, \"tokenizer\")\n",
    "os.makedirs(teacher_save_dir, exist_ok=True)\n",
    "os.makedirs(tokenizer_save_dir, exist_ok=True)\n",
    "\n",
    "trainer_teacher.model.save_pretrained(teacher_save_dir)\n",
    "tokenizer.save_pretrained(tokenizer_save_dir)\n",
    "print(\"Saved teacher model ->\", teacher_save_dir)\n",
    "print(\"Saved tokenizer ->\", tokenizer_save_dir)\n",
    "\n",
    "# Free GPU memory for student runs\n",
    "trainer_teacher.model.to(\"cpu\")\n",
    "gc.collect(); torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1759212349379,
     "user": {
      "displayName": "Yokeshwaran Goppinat",
      "userId": "14819290310669589320"
     },
     "user_tz": -330
    },
    "id": "BEWWfyJnIRMc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPI02SJKCp1MXbk8hZxBowF",
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
