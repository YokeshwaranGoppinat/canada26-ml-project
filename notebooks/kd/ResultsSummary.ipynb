{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "5bc95572f8ae41bd8d8b650dd5bca4dc",
      "7ff0c29a94c64095a005b8ea749722dd",
      "6d2a4cf32e1348e6834978c2080bab45",
      "9d3b168807cd428989f5b9914ab84910",
      "4ac73bcc73a048d595b3deea8115d755",
      "82d624167a704a4a9335ff2b5fd466df",
      "2df9bbf848284ac581a6155760b2f514",
      "c3833438da9d48aca6c4be14f6d567d0",
      "9456743fd1984bd78063709ff3ace100",
      "6e6e10ccb7d64b249c08142088ced978",
      "f6bbeb9fb87c4dff985c25d7899574ab",
      "628dc827e52f498b90e0e75da50e64f7",
      "a3b9bc6efdca47bcafc680b0f12cd280",
      "6391c15e7aa84711b00fee659b1c4e4a",
      "87bfd58f9450474bb50fec8b0d62b1ba",
      "00190ea167264433a36bfbabe1c00828",
      "7249e1889d6047b3b5376ebea2cf54e2",
      "d65b3854f11a4ea5be4001a40dfa63cd",
      "3c0988d5c04a44c2a0b640c54cebd1c9",
      "29d8a77260f74d268dd3f13714cb9178",
      "bd5a87400ef445c69e8430134e450d3f",
      "eef483aedb9d47b885b853d828fcda7a",
      "e50d18a0684443c7aaf355196a73867d",
      "d2b8e495e6b44c9486cd336fc4854d36",
      "1fc5a0d2ee144df9a7a312e43eb39bb0",
      "faf6f2df26bc45158fae7bfab2fe42ba",
      "131c3974cd5b4582ba38b2555c945cd9",
      "a2cdc79de046458f8e673cd64f3e55fe",
      "e2dd4be7699a448ab30eb0031871a83e",
      "eeb73669a4a2447982b2a42754a84594",
      "cc441c844fa54d5b83ee65b7074ff946",
      "21a9009f66c0426a909e62b9e724aae9",
      "98da7d36d49d4cd09bbbfcf0c732ae58",
      "ec9db32ae76b4c14b2b616c21d085053",
      "aae5be5e78034ff49c8f572e7e53ddf2",
      "a18d0f74c54d44fd93ba65dcdd7788d7",
      "1398d83386df4a97b73d5621b22259fc",
      "0bfd6e2006b54d26a2290a642f1f149d",
      "855490b7e70845b29c4114ca5a89d5de",
      "ad5f22474ed64a21972e3c91ff9ceeb4",
      "504798386cef44cfacc539398e593b82",
      "7a714f33d5bc4c6eb238bbd0711c038b",
      "c78649a59f73463195588b507cd7a777",
      "31c607af22b14291b7586f5bc2b44ad5",
      "0160a8f7b5594890b8998271840aee36",
      "cbd74f21bd974bfab3984ebeaa85406f",
      "684e817481cd4e0d8f5bf17d1b049000",
      "e8b5b63fcc1f404984eb16a5a1342e90",
      "a8391369f8a0498a8efce1fddcb86fb8",
      "b68ee3d509d144e88078f38efffc6859",
      "02c4ffcf1a7a41bdb54b457b1868f909",
      "c52479d34350437591456755f9bccd5a",
      "8b578e80a329494dab2e8a3062a40baf",
      "c7a002ef0ca94a7cb00a041ef1cf89cd",
      "72803e7d15bc448d9f967c62124479a2",
      "c32055da7a9e42ecbc883fd883b9d113",
      "a9cf2ac8165846908f6a65a19b166aed",
      "00000903afd247eb9878571ec2315eec",
      "b35a9e0b440741bc8fdbc4d5b5511e3c",
      "4e84dda329bc4d5492cf90760e9ea54e",
      "b89cfce968af428ab838e1112f1e6b2f",
      "0f69903b88864afa9ff8270fc730afa7",
      "41b5c86cde0f40acb590444d42f75bc1",
      "6039be06c88b4f4b910938cadac17ae5",
      "5c4e4b0a061a4396af4a547b95072dc3",
      "f29c5b74260d4b28a90fb3cc2779d77c",
      "3fe13ee7012444eebfe63c6e6dfbf5bc",
      "64710fe82cdf4a23b3948076f13ad429",
      "b5a058cec96f4333b3f81b553a86413a",
      "bc50efb450184de683f0461c911e94e3",
      "3b2505e338b8438eaeb28de81ecdfb4e",
      "be45da16dcb9402aa4b1874bac3014b3",
      "9fdf0f154dc645f2863faae04605c44c",
      "df4c6d63c9934534a2d28687b4831c00",
      "672014a48a9c4188a7227afae300aed3",
      "ec2dbbd6683a48fb903792a57ddf5d30",
      "6c5e4855371f47c9ad829e4b674afc51",
      "65c16f59f45644d7826088b0041c89a8",
      "1d52fdc4ab344a7b9fe050c1a955e1c9",
      "58bbe564f1164407b62a10ed16602da4",
      "05cafb206fa0452fa151cc6e500a0c80",
      "2979f6e76e4f448ca801b5b992e5a0b3",
      "1f523968d1c548dbaf90fd24016ab53d",
      "ea769b24b9ea4cccbc03760997f9dc38",
      "3b84bc42a5bd4e51a16a9d126b0fc04e",
      "43be1aa9983743cb97c5c679b2ceaf46",
      "8af8fd4e8b024a68983b72d85d72d23d",
      "f48e7e1092084e1c844e1f7c56d60b88",
      "c7e89e0b4ea6473d8301a1ca52fe9c38",
      "76ab5a331f9d4a3493af5dcf3ee898b5",
      "515e9e6902384039aba28844b08bcce2",
      "ffd2862fb3984fdb965f0cd0d5b031e1",
      "76a99fa3ebc64f0ab20c3a456afc4dce",
      "2410f5baa4b8442886d8bd2d12804ed4",
      "9f28973b1672449aa29ed8785c84f288",
      "a07c5129f96143e2957a857ba5ddd025",
      "85be749b229f46bda09738f844e796f8",
      "72392874942b45209c5eba0788086662",
      "85759090b0da4c6c89222ee606147113",
      "c2001b7514494e14b13c3cebe7cd96d2",
      "99c9368fb71740c3a6d139e491147e0f",
      "15e32d076bb3472e8a26fe56ff57e69e",
      "502a1d8a2f98495ebe98ee8e4b198dc0",
      "63462366b98a4ac89adc4fcae7067633",
      "2b4bdeda586e47d8abb47df4d4730f00",
      "58a500e819544830b3417502563319b4",
      "323ef1f2b41f441fb44ebe8187cd616f",
      "8faeaf820ec949eba0387af23fe56d2e",
      "785d9584727a425c842f53a519ee1612",
      "fd960c11154a4f0cac9cbc1ebb07ed71",
      "a83ce990b95643e7b85667b50219f5b0",
      "027affd37e0a479e84b28377a1be866d",
      "fd647d50dfeb41319052129b34559c0e",
      "edc9ad33394a47d29f4dc1cff7a3c0d8",
      "b7e98a2888754dbfa65c96c5f0b1feba",
      "aba0cd33f2ea4f57ab3765045093f35c",
      "619121c4d4da479ea92a38a44d062119",
      "8cd09db910b540a9b1a5457dc6a96f0f",
      "af3f88e23e1d4fafac2d8bed2d211e8c",
      "8410e95b057f43c590c6edfc04a0166a",
      "57aed7ee16464e1dbff616f4980b2165",
      "3c79ed1043f14e71a1bede8e5fc31349",
      "297d1e4e5b9b4cf690070d4f1de7dd28",
      "4de53cf7fe764b2fb65db3c34e95bad6",
      "700a1859738643a992ede54cf7537e26",
      "246de7de33da4507b987b0d6ed1da698",
      "551fe4931a0d4e4eafe8bd9e822c6aa1",
      "203adf87442c4058b1363fdcb3e8a5d2",
      "51848703a2164deca62509ef1a9007d0",
      "affa95c1b17d40a791f435cf430fe81c",
      "0636d5abc7d84008907088db46103095",
      "0418af1c3d764cd68bf44689068f0604",
      "62fbc23548574dcab333a165d53afcd3",
      "76392985b4be4b7489eb643714059ce0",
      "ba017a1fcefe4bc4b15c87248d7f539b",
      "662ebd2f9bd240f888f0c2fc1a4a88ea",
      "607043e0193e45949ccedb400a688847",
      "edaac52e5a93403d96b2bd43f5ae4b70",
      "e16d4a6520bb4571acfca5d6d8f0df07",
      "65f253b959b941d1b0cb031a81948fc7",
      "e62997ea8b44463b8658ce8d7cefad32",
      "231b83f65bf14e53a623ea55908ad1c6",
      "e2af0118483648ed8ad25bffd42123d7"
     ]
    },
    "executionInfo": {
     "elapsed": 225389,
     "status": "ok",
     "timestamp": 1759283819205,
     "user": {
      "displayName": "Yokeshwaran Goppinat",
      "userId": "14819290310669589320"
     },
     "user_tz": -330
    },
    "id": "j4RGRDauADDc",
    "outputId": "f749fe19-0085-4b73-a279-1832c9f8acfd"
   },
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Collate experiments: teacher (4-epoch) + NEW students only (relative drops)\n",
    "# Paste & run as single cell in Colab\n",
    "# ===========================\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "!pip install -q transformers datasets evaluate accelerate scikit-learn openpyxl\n",
    "\n",
    "import os, gc, re, torch, numpy as np, pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import evaluate\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ---------- User paths ----------\n",
    "DRIVE_BASE = \"/content/drive/MyDrive/Colab Notebooks/CodeMix\"\n",
    "test_csv  = os.path.join(DRIVE_BASE, \"test.csv\")\n",
    "\n",
    "# NEW: use the 4-epoch teacher folder\n",
    "teacher_base_dir = os.path.join(DRIVE_BASE, \"results_teacher_4epoch\", \"model\")\n",
    "\n",
    "# Student runs root\n",
    "STUDENTS_BASE = os.path.join(DRIVE_BASE, \"results_students\")\n",
    "\n",
    "# Output files\n",
    "OUT_CSV  = os.path.join(DRIVE_BASE, \"distillation_results_rel_new_only.csv\")\n",
    "OUT_XLSX = os.path.join(DRIVE_BASE, \"distillation_results_rel_new_only.xlsx\")\n",
    "\n",
    "CHECKPOINT = \"distilbert-base-multilingual-cased\"\n",
    "MAX_LEN = 64\n",
    "EVAL_BATCH = 32\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# ---------- Load test ----------\n",
    "if not os.path.exists(test_csv):\n",
    "    raise FileNotFoundError(f\"Test CSV not found at {test_csv}. Run data-prep notebook first.\")\n",
    "test_df = pd.read_csv(test_csv)\n",
    "if \"review\" not in test_df.columns or \"label\" not in test_df.columns:\n",
    "    raise RuntimeError(\"Expecting test.csv to have columns 'review' and 'label'.\")\n",
    "\n",
    "test_texts = test_df[\"review\"].astype(str).tolist()\n",
    "test_labels = test_df[\"label\"].astype(int).tolist()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(CHECKPOINT)\n",
    "enc = tokenizer(test_texts, padding=\"max_length\", truncation=True, max_length=MAX_LEN, return_tensors=\"pt\")\n",
    "indices = list(range(len(test_texts)))\n",
    "batches = [indices[i:i+EVAL_BATCH] for i in range(0, len(test_texts), EVAL_BATCH)]\n",
    "\n",
    "# ---------- Metrics ----------\n",
    "acc_metric = evaluate.load(\"accuracy\")\n",
    "f1_metric  = evaluate.load(\"f1\")\n",
    "\n",
    "def evaluate_model(model, device):\n",
    "    model.to(device).eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx in tqdm(batches, desc=\"eval batches\"):\n",
    "            logits = model(\n",
    "                input_ids=enc[\"input_ids\"][batch_idx].to(device),\n",
    "                attention_mask=enc[\"attention_mask\"][batch_idx].to(device)\n",
    "            ).logits\n",
    "            preds = torch.argmax(logits, dim=-1).cpu().numpy().tolist()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend([test_labels[i] for i in batch_idx])\n",
    "    acc = acc_metric.compute(predictions=all_preds, references=all_labels)[\"accuracy\"]\n",
    "    f1  = f1_metric.compute(predictions=all_preds, references=all_labels, average=\"macro\")[\"f1\"]\n",
    "    return float(acc), float(f1)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "def extract_layers(model):\n",
    "    cfg = getattr(model, \"config\", None)\n",
    "    if cfg is None: return None\n",
    "    return getattr(cfg, \"num_hidden_layers\", None) or getattr(cfg, \"n_layers\", None) or getattr(cfg, \"num_layers\", None)\n",
    "\n",
    "# ---------- Loader (robust to local folder structure) ----------\n",
    "def load_local_model(folder):\n",
    "    tried = []\n",
    "    try:\n",
    "        return AutoModelForSequenceClassification.from_pretrained(\n",
    "            folder, local_files_only=True, output_hidden_states=True, output_attentions=True\n",
    "        )\n",
    "    except Exception as e:\n",
    "        tried.append((folder, str(e)))\n",
    "    for alt in [os.path.join(folder, \"student_model\"), os.path.join(folder, \"model\")]:\n",
    "        if os.path.isdir(alt):\n",
    "            try:\n",
    "                return AutoModelForSequenceClassification.from_pretrained(\n",
    "                    alt, local_files_only=True, output_hidden_states=True, output_attentions=True\n",
    "                )\n",
    "            except Exception as e:\n",
    "                tried.append((alt, str(e)))\n",
    "    if os.path.isdir(folder):\n",
    "        ckpts = sorted([os.path.join(folder, d) for d in os.listdir(folder) if d.startswith(\"checkpoint\")])\n",
    "        for c in reversed(ckpts):\n",
    "            try:\n",
    "                return AutoModelForSequenceClassification.from_pretrained(\n",
    "                    c, local_files_only=True, output_hidden_states=True, output_attentions=True\n",
    "                )\n",
    "            except Exception as e:\n",
    "                tried.append((c, str(e)))\n",
    "    raise RuntimeError(f\"Cannot load model from {folder}. Attempts: {tried}\")\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "def label_from_name(name):\n",
    "    n = os.path.basename(name).lower()\n",
    "    if \"baseline\" in n: return \"Baseline\"\n",
    "    if \"soft\" in n:     return \"Soft\"\n",
    "    if \"hidden\" in n:   return \"Hidden\"\n",
    "    if \"full\" in n:     return \"Full\"\n",
    "    if \"embed\" in n or \"embedding\" in n: return \"Embedding\"\n",
    "    if \"attn\" in n or \"attention\" in n:  return \"Attention\"\n",
    "    return os.path.basename(name)\n",
    "\n",
    "def parse_meta_from_name(name):\n",
    "    n = os.path.basename(name)\n",
    "    layers = None; seed = None\n",
    "    m = re.search(r\"layers(\\d+)\", n)\n",
    "    if m:  layers = int(m.group(1))\n",
    "    m2 = re.search(r\"seed(\\d+)\", n)\n",
    "    if m2: seed = int(m2.group(1))\n",
    "    return layers, seed\n",
    "\n",
    "# ---------- Evaluate ----------\n",
    "records = []\n",
    "\n",
    "# Teacher (4-epoch)\n",
    "if not os.path.isdir(teacher_base_dir):\n",
    "    raise RuntimeError(f\"Teacher (4-epoch) not found at {teacher_base_dir}\")\n",
    "\n",
    "print(\"Loading teacher (4-epoch) from:\", teacher_base_dir)\n",
    "teacher = load_local_model(teacher_base_dir)\n",
    "teacher_acc, teacher_f1 = evaluate_model(teacher, device)\n",
    "teacher_params = count_parameters(teacher) / 1e6\n",
    "teacher_layers = extract_layers(teacher)\n",
    "\n",
    "records.append({\n",
    "    \"Label\": \"Teacher\",\n",
    "    \"Accuracy\": teacher_acc,\n",
    "    \"Macro-F1\": teacher_f1,\n",
    "    \"RelAccDrop%\": None,\n",
    "    \"RelF1Drop%\": None,\n",
    "    \"Layers\": teacher_layers,\n",
    "    \"Params(M)\": round(teacher_params, 2),\n",
    "    \"ParamReduction%\": None,\n",
    "    \"Path\": teacher_base_dir,\n",
    "    \"Seed\": None\n",
    "})\n",
    "\n",
    "teacher.to(\"cpu\"); del teacher; gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "# Students: ONLY the *new* runs tagged with layers# AND teacher4epoch in name\n",
    "if os.path.isdir(STUDENTS_BASE):\n",
    "    all_dirs = sorted([os.path.join(STUDENTS_BASE, d) for d in os.listdir(STUDENTS_BASE) if os.path.isdir(os.path.join(STUDENTS_BASE, d))])\n",
    "else:\n",
    "    all_dirs = []\n",
    "\n",
    "new_student_dirs = [\n",
    "    p for p in all_dirs\n",
    "    if re.search(r\"layers\\d+\", os.path.basename(p).lower()) and (\"teacher4epoch\" in os.path.basename(p).lower())\n",
    "]\n",
    "\n",
    "if not new_student_dirs:\n",
    "    print(\"No NEW student folders found (need names containing both 'layers#' and 'teacher4epoch').\")\n",
    "else:\n",
    "    print(\"Evaluating NEW student folders:\")\n",
    "    for p in new_student_dirs: print(\"  \", p)\n",
    "\n",
    "for path in new_student_dirs:\n",
    "    try:\n",
    "        student = load_local_model(path)\n",
    "    except Exception as e:\n",
    "        print(\"  Skipping (cannot load):\", path, \"=>\", e)\n",
    "        continue\n",
    "\n",
    "    s_acc, s_f1 = evaluate_model(student, device)\n",
    "    s_params = count_parameters(student) / 1e6\n",
    "    s_layers = extract_layers(student)\n",
    "    parsed_layers, parsed_seed = parse_meta_from_name(path)\n",
    "    if parsed_layers is not None:\n",
    "        s_layers = parsed_layers\n",
    "\n",
    "    rel_acc = ((teacher_acc - s_acc) / teacher_acc * 100.0)\n",
    "    rel_f1  = ((teacher_f1 - s_f1) / teacher_f1 * 100.0)\n",
    "    param_red = (1.0 - (s_params / teacher_params)) * 100.0\n",
    "\n",
    "    records.append({\n",
    "        \"Label\": label_from_name(path),\n",
    "        \"Accuracy\": s_acc,\n",
    "        \"Macro-F1\": s_f1,\n",
    "        \"RelAccDrop%\": round(rel_acc, 4),\n",
    "        \"RelF1Drop%\": round(rel_f1, 4),\n",
    "        \"Layers\": s_layers,\n",
    "        \"Params(M)\": round(s_params, 2),\n",
    "        \"ParamReduction%\": round(param_red, 2),\n",
    "        \"Path\": path,\n",
    "        \"Seed\": parsed_seed\n",
    "    })\n",
    "\n",
    "    student.to(\"cpu\"); del student; gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "# ---------- Summarise ----------\n",
    "df = pd.DataFrame(records)\n",
    "if df.empty:\n",
    "    print(\"No models evaluated.\")\n",
    "else:\n",
    "    order = [\"Teacher\",\"Baseline\",\"Soft\",\"Hidden\",\"Full\",\"Embedding\",\"Attention\"]\n",
    "    df[\"order\"] = df[\"Label\"].apply(lambda x: order.index(x) if x in order else len(order))\n",
    "    df = df.sort_values([\"order\",\"Label\"]).drop(columns=\"order\").reset_index(drop=True)\n",
    "\n",
    "    df.to_csv(OUT_CSV, index=False)\n",
    "    try:\n",
    "        df.to_excel(OUT_XLSX, index=False)\n",
    "    except Exception as e:\n",
    "        print(\"Excel save failed:\", e)\n",
    "\n",
    "    print(\"\\nSaved results to:\\n\", OUT_CSV, \"\\n\", OUT_XLSX)\n",
    "    pd.set_option(\"display.max_colwidth\", 160)\n",
    "    display(df)\n",
    "\n",
    "print(\"\\nDone.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pr48yG_vine0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPJHNsNE2S4dousGo8W2f7f",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
